{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a011f3",
   "metadata": {},
   "source": [
    "PyTorch 深度学习模型的建立范式\n",
    "建立模型有一个范式，这个非常简单的知识为数据建模和理解 PyTorch API 提供了支撑。\n",
    "\n",
    "模型建立范式中的五个步骤如下：\n",
    "\n",
    "准备数据。\n",
    "定义模型。\n",
    "训练模型。\n",
    "评估模型。\n",
    "做出预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb856b",
   "metadata": {},
   "source": [
    "1. 准备数据\n",
    "第一步是加载和准备数据。\n",
    "\n",
    "神经网络模型需要输入数据和输出数据。\n",
    "\n",
    "你可以使用标准 Python 库来加载和准备多维数据，例如 CSV 文件。\n",
    "\n",
    "Pandas 可用于加载你的 CSV 文件，Scikit-Learn 中的工具可用于编码分类数据，例如对标签分类。\n",
    "\n",
    "PyTorch 提供了 Dataset 类，你可以扩展和自定义该类以加载你的数据集。\n",
    "\n",
    "例如，数据集对象的构造函数可以加载你的数据文件（例如 CSV 文件）。然后，你可以覆盖可用于获取数据集长度（行数或样本数）的 __len__() 函数，以及用于按索引获取特定样本的 __getitem__() 函数。\n",
    "\n",
    "加载数据集时，你还可以执行任何所需的转换，例如缩放或编码。\n",
    "\n",
    "下面提供了自定义数据集类的框架。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafbffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 定义数据集\n",
    "class CSVDataset(Dataset):\n",
    "    # 导入数据集\n",
    "    def __init__(self, path):\n",
    "        # 导入传入路径的数据集为 Pandas DataFrame 格式\n",
    "        dataset = pd.read_csv(path, header=None)\n",
    "        # 设置神经网络的输入与输出\n",
    "        self.X = dataset.values[:, :-1]  # 根据你的数据集定义输入属性\n",
    "        self.y = dataset.values[:, -1]  # 根据你的数据集定义输出属性\n",
    "        # 确保输入的数据是浮点型\n",
    "        self.X = self.X.astype('float32')\n",
    "        # 使用浮点型标签编码原输出\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    " \n",
    "    # 定义获得数据集长度的方法\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # 定义获得某一行数据的方法\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "    \n",
    "    # 在类内部定义划分训练集和测试集的方法，在本例中，训练集比例为 0.67，测试集比例为 0.33\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # 确定训练集和测试集的尺寸\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # 根据尺寸划分训练集和测试集并返回\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68919b67",
   "metadata": {},
   "source": [
    "让我们运行一下定义的 CSVDataset() 类中的各方法以加深理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b8556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入矩阵的形状是：(150, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义数据集路径（在本例中，数据集需为 csv 文件）\n",
    "data_path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n",
    "# 实例化数据集\n",
    "dataset = CSVDataset(data_path)\n",
    "print(f'输入矩阵的形状是：{dataset.X.shape}')\n",
    "dataset.X  # 查看输入矩阵 dataset.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c406aae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出矩阵的形状是：(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'输出矩阵的形状是：{dataset.y.shape}')\n",
    "dataset.y  # 查看输出矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f82c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "# len() 方法本质上是调用类内部的 __len__() 方法，所以以下方法是等效的。\n",
    "print(len(dataset))\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d6601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([5.9, 3. , 5.1, 1.8], dtype=float32), np.int64(2)]\n",
      "[array([5.9, 3. , 5.1, 1.8], dtype=float32), np.int64(2)]\n"
     ]
    }
   ],
   "source": [
    "# dataset[] 方法本质上是调用类内部的 __getitem__ 方法，所以以下方法是等效的。\n",
    "print(dataset[149])\n",
    "print(dataset.__getitem__(149))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b6ae8",
   "metadata": {},
   "source": [
    "加载后，PyTorch 提供 DataLoader 类，用于在模型训练和评估期间导航数据集实例。\n",
    "\n",
    "可以为训练数据集、测试数据集甚至验证数据集创建 DataLoader 实例。\n",
    "\n",
    "random_split() 函数可用于将数据集拆分为训练集和测试集。\n",
    "\n",
    "拆分后，将数据集中 batch 及其 size 提供给 DataLoader，并可选择是否应在每个 epoch 对数据进行随机排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a667b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "划分的训练集的数据类型是：<class 'torch.utils.data.dataset.Subset'>\n",
      "划分的训练集长度是：100\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "...\n",
    "# 确定训练集和测试集的尺寸\n",
    "n_test = 0.33  # 在本例中，训练集比例为 0.67，测试集比例为 0.33\n",
    "test_size = round(n_test * len(dataset.X))\n",
    "train_size = len(dataset.X) - test_size\n",
    "\n",
    "# 根据尺寸划分训练集和测试集并返回\n",
    "train, test = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 让我们查看一下创建的训练集的类型和长度\n",
    "print(f'划分的训练集的数据类型是：{type(train)}')\n",
    "print(f'划分的训练集长度是：{len(train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a88b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([5.8, 2.7, 4.1, 1. ], dtype=float32), np.int64(1)],\n",
       " [array([5.1, 3.5, 1.4, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([4.8, 3.4, 1.6, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([6.1, 2.8, 4. , 1.3], dtype=float32), np.int64(1)],\n",
       " [array([6.3, 2.5, 4.9, 1.5], dtype=float32), np.int64(1)],\n",
       " [array([5.6, 2.8, 4.9, 2. ], dtype=float32), np.int64(2)],\n",
       " [array([5.1, 3.3, 1.7, 0.5], dtype=float32), np.int64(0)],\n",
       " [array([5.4, 3.4, 1.7, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5.7, 2.5, 5. , 2. ], dtype=float32), np.int64(2)],\n",
       " [array([4.4, 3.2, 1.3, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([6.8, 3.2, 5.9, 2.3], dtype=float32), np.int64(2)],\n",
       " [array([6. , 3.4, 4.5, 1.6], dtype=float32), np.int64(1)],\n",
       " [array([5.6, 2.5, 3.9, 1.1], dtype=float32), np.int64(1)],\n",
       " [array([6.9, 3.2, 5.7, 2.3], dtype=float32), np.int64(2)],\n",
       " [array([6.1, 3. , 4.9, 1.8], dtype=float32), np.int64(2)],\n",
       " [array([6.3, 2.7, 4.9, 1.8], dtype=float32), np.int64(2)],\n",
       " [array([5.6, 2.9, 3.6, 1.3], dtype=float32), np.int64(1)],\n",
       " [array([6.4, 3.2, 5.3, 2.3], dtype=float32), np.int64(2)],\n",
       " [array([5.7, 2.8, 4.1, 1.3], dtype=float32), np.int64(1)],\n",
       " [array([7. , 3.2, 4.7, 1.4], dtype=float32), np.int64(1)],\n",
       " [array([5. , 2.3, 3.3, 1. ], dtype=float32), np.int64(1)],\n",
       " [array([5.4, 3.7, 1.5, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5.5, 2.5, 4. , 1.3], dtype=float32), np.int64(1)],\n",
       " [array([4.6, 3.2, 1.4, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([7.6, 3. , 6.6, 2.1], dtype=float32), np.int64(2)],\n",
       " [array([4.9, 3.1, 1.5, 0.1], dtype=float32), np.int64(0)],\n",
       " [array([5.1, 3.4, 1.5, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([7.1, 3. , 5.9, 2.1], dtype=float32), np.int64(2)],\n",
       " [array([4.6, 3.6, 1. , 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5.1, 3.8, 1.5, 0.3], dtype=float32), np.int64(0)],\n",
       " [array([5. , 3.5, 1.3, 0.3], dtype=float32), np.int64(0)],\n",
       " [array([6.5, 3.2, 5.1, 2. ], dtype=float32), np.int64(2)],\n",
       " [array([5.6, 3. , 4.5, 1.5], dtype=float32), np.int64(1)],\n",
       " [array([5. , 3.2, 1.2, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([6.2, 2.8, 4.8, 1.8], dtype=float32), np.int64(2)],\n",
       " [array([6.3, 2.3, 4.4, 1.3], dtype=float32), np.int64(1)],\n",
       " [array([5.7, 2.9, 4.2, 1.3], dtype=float32), np.int64(1)],\n",
       " [array([6.7, 3.1, 4.4, 1.4], dtype=float32), np.int64(1)],\n",
       " [array([4.8, 3.4, 1.9, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5. , 3.6, 1.4, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([6.3, 2.5, 5. , 1.9], dtype=float32), np.int64(2)],\n",
       " [array([7.2, 3. , 5.8, 1.6], dtype=float32), np.int64(2)],\n",
       " [array([6.4, 3.1, 5.5, 1.8], dtype=float32), np.int64(2)],\n",
       " [array([5.7, 4.4, 1.5, 0.4], dtype=float32), np.int64(0)],\n",
       " [array([7.3, 2.9, 6.3, 1.8], dtype=float32), np.int64(2)],\n",
       " [array([6.7, 3.3, 5.7, 2.5], dtype=float32), np.int64(2)],\n",
       " [array([5.5, 4.2, 1.4, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([7.2, 3.2, 6. , 1.8], dtype=float32), np.int64(2)],\n",
       " [array([4.9, 2.5, 4.5, 1.7], dtype=float32), np.int64(2)],\n",
       " [array([5. , 3.4, 1.6, 0.4], dtype=float32), np.int64(0)],\n",
       " [array([6.3, 2.9, 5.6, 1.8], dtype=float32), np.int64(2)],\n",
       " [array([6.7, 3.1, 5.6, 2.4], dtype=float32), np.int64(2)],\n",
       " [array([5.8, 4. , 1.2, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([7.7, 3.8, 6.7, 2.2], dtype=float32), np.int64(2)],\n",
       " [array([6. , 2.2, 4. , 1. ], dtype=float32), np.int64(1)],\n",
       " [array([7.7, 2.8, 6.7, 2. ], dtype=float32), np.int64(2)],\n",
       " [array([4.6, 3.1, 1.5, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([4.9, 3.1, 1.5, 0.1], dtype=float32), np.int64(0)],\n",
       " [array([5.6, 2.7, 4.2, 1.3], dtype=float32), np.int64(1)],\n",
       " [array([4.5, 2.3, 1.3, 0.3], dtype=float32), np.int64(0)],\n",
       " [array([6.7, 3. , 5. , 1.7], dtype=float32), np.int64(1)],\n",
       " [array([5.7, 2.6, 3.5, 1. ], dtype=float32), np.int64(1)],\n",
       " [array([5.8, 2.7, 5.1, 1.9], dtype=float32), np.int64(2)],\n",
       " [array([6. , 2.2, 5. , 1.5], dtype=float32), np.int64(2)],\n",
       " [array([5.2, 3.4, 1.4, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5.5, 2.4, 3.7, 1. ], dtype=float32), np.int64(1)],\n",
       " [array([5.8, 2.6, 4. , 1.2], dtype=float32), np.int64(1)],\n",
       " [array([4.9, 3. , 1.4, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([6.5, 3. , 5.2, 2. ], dtype=float32), np.int64(2)],\n",
       " [array([6.4, 2.7, 5.3, 1.9], dtype=float32), np.int64(2)],\n",
       " [array([5.2, 2.7, 3.9, 1.4], dtype=float32), np.int64(1)],\n",
       " [array([6.7, 2.5, 5.8, 1.8], dtype=float32), np.int64(2)],\n",
       " [array([5.8, 2.7, 3.9, 1.2], dtype=float32), np.int64(1)],\n",
       " [array([6.5, 2.8, 4.6, 1.5], dtype=float32), np.int64(1)],\n",
       " [array([5.1, 3.7, 1.5, 0.4], dtype=float32), np.int64(0)],\n",
       " [array([6. , 2.7, 5.1, 1.6], dtype=float32), np.int64(1)],\n",
       " [array([5.7, 3.8, 1.7, 0.3], dtype=float32), np.int64(0)],\n",
       " [array([6.3, 3.3, 4.7, 1.6], dtype=float32), np.int64(1)],\n",
       " [array([6.7, 3. , 5.2, 2.3], dtype=float32), np.int64(2)],\n",
       " [array([6.4, 2.9, 4.3, 1.3], dtype=float32), np.int64(1)],\n",
       " [array([6.5, 3. , 5.8, 2.2], dtype=float32), np.int64(2)],\n",
       " [array([5.9, 3. , 4.2, 1.5], dtype=float32), np.int64(1)],\n",
       " [array([6.1, 2.6, 5.6, 1.4], dtype=float32), np.int64(2)],\n",
       " [array([4.8, 3.1, 1.6, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5.7, 3. , 4.2, 1.2], dtype=float32), np.int64(1)],\n",
       " [array([5.4, 3.9, 1.3, 0.4], dtype=float32), np.int64(0)],\n",
       " [array([4.3, 3. , 1.1, 0.1], dtype=float32), np.int64(0)],\n",
       " [array([6.8, 3. , 5.5, 2.1], dtype=float32), np.int64(2)],\n",
       " [array([5. , 3.4, 1.5, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5.4, 3.9, 1.7, 0.4], dtype=float32), np.int64(0)],\n",
       " [array([5. , 3. , 1.6, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([6.1, 2.9, 4.7, 1.4], dtype=float32), np.int64(1)],\n",
       " [array([6.9, 3.1, 5.4, 2.1], dtype=float32), np.int64(2)],\n",
       " [array([4.8, 3. , 1.4, 0.3], dtype=float32), np.int64(0)],\n",
       " [array([5.5, 2.3, 4. , 1.3], dtype=float32), np.int64(1)],\n",
       " [array([4.7, 3.2, 1.6, 0.2], dtype=float32), np.int64(0)],\n",
       " [array([5.1, 2.5, 3. , 1.1], dtype=float32), np.int64(1)],\n",
       " [array([6.4, 2.8, 5.6, 2.2], dtype=float32), np.int64(2)],\n",
       " [array([6. , 2.9, 4.5, 1.5], dtype=float32), np.int64(1)],\n",
       " [array([6.6, 2.9, 4.6, 1.3], dtype=float32), np.int64(1)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train)  # 查看一下划分的训练集\n",
    "\n",
    "# 你可以用同样的方法查看一下划分得到的测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeabedf",
   "metadata": {},
   "source": [
    "例如，我们可以通过传入数据集中的选定行来定义 DataLoader。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 50\n"
     ]
    }
   ],
   "source": [
    "# 为训练集和测试集创建 DataLoader\n",
    "train_dl = DataLoader(train, batch_size=32, shuffle=True)# 训练集数据加载器，批量大小为32，随机打乱\n",
    "test_dl = DataLoader(test, batch_size=1024, shuffle=False)# 测试集数据加载器，批量大小为1024，不随机打乱\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ba8fe",
   "metadata": {},
   "source": [
    "定义后，可以循环 DataLoader，每次迭代生成一批样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a25a1a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 个 batch 有 32 个数据，其中输入矩阵的形状是 torch.Size([32, 4])，输出矩阵的形状是 torch.Size([32])\n",
      "第 1 个 batch 有 32 个数据，其中输入矩阵的形状是 torch.Size([32, 4])，输出矩阵的形状是 torch.Size([32])\n",
      "第 2 个 batch 有 32 个数据，其中输入矩阵的形状是 torch.Size([32, 4])，输出矩阵的形状是 torch.Size([32])\n",
      "第 3 个 batch 有 4 个数据，其中输入矩阵的形状是 torch.Size([4, 4])，输出矩阵的形状是 torch.Size([4])\n",
      "共有 4 个 batches\n"
     ]
    }
   ],
   "source": [
    "# 在本例中，train_dl 的 batch_size 为 32，数据将随机排序。让我们来查看一下 train_dl\n",
    "n_inputs = len(train_dl)\n",
    "for i, (inputs, targets) in enumerate(train_dl):  \n",
    "    print(f'第 {i} 个 batch 有 {len(inputs)} 个数据，其中输入矩阵的形状是 {inputs.shape}，输出矩阵的形状是 {targets.shape}')\n",
    "print(f'共有 {n_inputs} 个 batches')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801509b7",
   "metadata": {},
   "source": [
    "enumerate() 函数是 Python 内置函数，用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个有索引的序列，同时列出数据和数据下标。多用在 for 循环中。\n",
    "\n",
    "尝试在本 Notebook 中运行以下示例并理解 enumerate() 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662be699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ('Spring', 'Green')), (1, ('Summer', 'Red')), (2, ('Fall', 'Yellow')), (3, ('Winter', 'White'))]\n",
      "--------\n",
      "My impression 1 about Spring is Green.\n",
      "My impression 2 about Summer is Red.\n",
      "My impression 3 about Fall is Yellow.\n",
      "My impression 4 about Winter is White.\n"
     ]
    }
   ],
   "source": [
    "seasons = [('Spring', 'Green'), \n",
    "           ('Summer', 'Red'), \n",
    "           ('Fall', 'Yellow'), \n",
    "           ('Winter', 'White')\n",
    "           ]\n",
    "print(list(enumerate(seasons, start=0)))  # start 参数设置序列从 1 开始，不填则默认从 0 开始\n",
    "print('--------')\n",
    "\n",
    "# 再在 for 循环中看看 enumerate 函数的效果\n",
    "for i, (season, color) in enumerate(seasons, start=1):\n",
    "    print(f'My impression {i} about {season} is {color}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f52ad",
   "metadata": {},
   "source": [
    "2. 定义模型\n",
    "在 PyTorch 中定义模型的习惯用法是定义一个继承 Module 类的 Python class 。\n",
    "\n",
    "你构造的类定义了模型的层，forward() 函数需要覆写以定义在模型层中的输入参数的前向传播。\n",
    "\n",
    "许多层都可用，例如用于全连接层的 Linear，用于卷积层的 Conv2d，用于池化层的 MaxPool2d。\n",
    "\n",
    "激活函数也可以定义为层，例如 ReLU, Softmax, 和 Sigmoid.\n",
    "\n",
    "在构造函数中定义给定层后，也可以初始化给定层的权重。\n",
    "\n",
    "常见的例子包括 Xavier 和 He weight 权重初始化方案。例如：xavier_uniform_(self.layer.weight)\n",
    "\n",
    "下面是一个简单的单层 MLP 模型的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c92f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "# 定义模型\n",
    "class MLP(Module):\n",
    "    # 定义模型属性\n",
    "    def __init__(self, n_inputs):\n",
    "        super().__init__()\n",
    "        # 第一个隐藏层\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # 第二个隐藏层\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # 第三层\n",
    "        self.hidden3 = Linear(8, 3)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Softmax(dim=1)\n",
    " \n",
    "    # 前向传播方法\n",
    "    def forward(self, X):\n",
    "        # 输入到第一个隐藏层\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # 第二个隐藏层\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # 输出层\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e282af",
   "metadata": {},
   "source": [
    "3. 训练模型\n",
    "训练过程要求你定义 损失函数 和 优化算法 。\n",
    "\n",
    "常见的损失函数包括：\n",
    "\n",
    "BCELoss: 用于二元分类的 二元交叉熵损失 (Binary Cross-Entropy Loss)\n",
    "CrossEntropyLoss: 用于多元分类的 多元交叉熵损失 (Categorical Cross-Entropy Loss)\n",
    "MSELoss: 用于回归的 均方损失 (Mean squared loss)\n",
    "\n",
    "使用 随机梯度下降 进行优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f882b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "...\n",
    "model = MLP(n_inputs=n_inputs)\n",
    "# 定义优化器\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab632b",
   "metadata": {},
   "source": [
    "训练模型涉及枚举训练数据集的 DataLoader。\n",
    "\n",
    "首先，需要为大量的 training epochs 建立一个循环。然后，需要为每个 mini-batch 建立一个内部循环，用于随机梯度下降。\n",
    "\n",
    "模型的每次更新都涉及相同的常规模式，包括：\n",
    "\n",
    "清除最后一个误差梯度。\n",
    "前向传播并计算模型输出。\n",
    "计算模型输出的损失。\n",
    "通过模型反向传播误差。\n",
    "更新模型以减少损失。\n",
    "例如：\n",
    "# 梯度清除\n",
    "optimizer.zero_grad()\n",
    "# 计算模型输出\n",
    "yhat = model(inputs)\n",
    "# 计算损失\n",
    "loss = criterion(yhat, targets)\n",
    "# 贡献度分配\n",
    "loss.backward()\n",
    "# 升级模型权重\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc63129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 枚举 epochs\n",
    "for epoch in range(500):\n",
    "    # 枚举 mini-batches\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        # 梯度清除\n",
    "        optimizer.zero_grad()\n",
    "        # 计算模型输出\n",
    "        yhat = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criterion(yhat, targets)\n",
    "        # 贡献度分配\n",
    "        loss.backward()\n",
    "        # 升级模型权重\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3226bb",
   "metadata": {},
   "source": [
    "4. 评估模型\n",
    "模型拟合后，可以在测试数据集上对其进行评估。\n",
    "\n",
    "可以通过使用测试集的 DataLoader 收集测试集的预测值，然后比较模型预测值与测试集的预期值并计算评价指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score    \n",
    "\n",
    "predictions, actuals = list(), list()  # 实例化预测值列表和预期值列表\n",
    "        \n",
    "for i, (inputs, targets) in enumerate(test_dl):\n",
    "    # 在测试集上评估模型\n",
    "    yhat = model(inputs)\n",
    "    # 转化为 numpy 数据类型\n",
    "    yhat = yhat.detach().numpy()\n",
    "    actual = targets.numpy()\n",
    "    # 转换为类标签\n",
    "    yhat = argmax(yhat, axis=1)\n",
    "    # 为 stack reshape 矩阵\n",
    "    actual = actual.reshape((len(actual), 1))\n",
    "    yhat = yhat.reshape((len(yhat), 1))\n",
    "    # 保存数据\n",
    "    predictions.append(yhat)\n",
    "    actuals.append(actual)\n",
    "\n",
    "predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "# 计算准确度\n",
    "acc = accuracy_score(actuals, predictions)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe661e8",
   "metadata": {},
   "source": [
    "5. 做出预测\n",
    "拟合模型可用于对新数据进行预测。\n",
    "\n",
    "例如，您可能有单个图像或一行数据，并且想要进行预测。\n",
    "\n",
    "这需要您将数据包装在 PyTorch Tensor 数据结构中。\n",
    "\n",
    "Tensor 只是用于保存 NumPy 数组类型的数据的 PyTorch 版本。它还允许您在模型图中执行自动微分任务，例如在训练模型时调用 backward()。\n",
    "\n",
    "预测也将是一个 Tensor，尽管您可以通过在自动微分图中分离张量并调用 NumPy 函数来检索 NumPy 数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2768f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "\n",
    "...\n",
    "row = [5.1,3.5,1.4,0.2]\n",
    "# 将数据转化为 Tensor\n",
    "row = Tensor([row])\n",
    "# 做出预测\n",
    "yhat = model(row)\n",
    "# 重写为 Numpy Array 格式\n",
    "yhat = yhat.detach().numpy()\n",
    "\n",
    "print(f'各标签可能的概率： {yhat} (最可能的种类：class={argmax(yhat)})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
