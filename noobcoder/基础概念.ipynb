{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#库导入\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbba3f7",
   "metadata": {},
   "source": [
    "简单的全连接神经网络（Fully Connected Network）:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db92c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.Linear(in_features, out_features):全连接层，输入 in_features 个特征，输出 out_features 个特征。\n",
    "nn.Conv2d(in_channels, out_channels, kernel_size):2D 卷积层，用于图像处理。\n",
    "nn.MaxPool2d(kernel_size):2D 最大池化层，用于降维。\n",
    "nn.ReLU():ReLU 激活函数，常用于隐藏层。\n",
    "nn.Softmax(dim):Softmax 激活函数，通常用于输出层，适用于多类分类问题。\n",
    "\"\"\"\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 定义一个输入层到隐藏层的全连接层\n",
    "        self.fc1 = nn.Linear(2, 2)  # 输入 2 个特征，输出 2 个特征\n",
    "        # 定义一个隐藏层到输出层的全连接层\n",
    "        self.fc2 = nn.Linear(2, 1)  # 输入 2 个特征，输出 1 个预测值\n",
    "   \n",
    "    def forward(self, x):\n",
    "        # 前向传播过程\n",
    "        x = torch.relu(self.fc1(x))  # 使用 ReLU 激活函数\n",
    "        x = self.fc2(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建模型实例\n",
    "    model = SimpleNN()\n",
    "\n",
    "    # 打印模型\n",
    "    print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fadbb8",
   "metadata": {},
   "source": [
    "激活函数（Activation Function）\n",
    "激活函数决定了神经元是否应该被激活。它们是非线性函数，使得神经网络能够学习和执行更复杂的任务。常见的激活函数包括：\n",
    "\n",
    "Sigmoid：用于二分类问题，输出值在 0 和 1 之间。\n",
    "Tanh：输出值在 -1 和 1 之间，常用于输出层之前。\n",
    "ReLU（Rectified Linear Unit）：目前最流行的激活函数之一，定义为 f(x) = max(0, x)，有助于解决梯度消失问题。\n",
    "Softmax：常用于多分类问题的输出层，将输出转换为概率分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "input_tensor = torch.randn(1, 3)\n",
    "# ReLU 激活\n",
    "output_ReLU = F.relu(input_tensor)\n",
    "\n",
    "# Sigmoid 激活\n",
    "output_Sigmoid = torch.sigmoid(input_tensor)\n",
    "\n",
    "# Tanh 激活\n",
    "output_Tanh = torch.tanh(input_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ddc99",
   "metadata": {},
   "source": [
    "损失函数（Loss Function）\n",
    "损失函数用于衡量模型的预测值与真实值之间的差异。\n",
    "\n",
    "常见的损失函数包括：\n",
    "\n",
    "均方误差（MSELoss）：回归问题常用，计算输出与目标值的平方差。\n",
    "交叉熵损失（CrossEntropyLoss）：分类问题常用，计算输出和真实标签之间的交叉熵。\n",
    "BCEWithLogitsLoss：二分类问题，结合了 Sigmoid 激活和二元交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159cb7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 均方误差损失\n",
    "criterion_MSELoss = nn.MSELoss()\n",
    "\n",
    "# 交叉熵损失\n",
    "criterion_CrossEntropyLoss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 二分类交叉熵损失\n",
    "criterion_BCEWithLogitsLoss = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73c81e",
   "metadata": {},
   "source": [
    "优化器（Optimizer）\n",
    "优化器负责在训练过程中更新网络的权重和偏置。\n",
    "\n",
    "常见的优化器包括：\n",
    "\n",
    "SGD（随机梯度下降）\n",
    "Adam（自适应矩估计）\n",
    "RMSprop（均方根传播）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 使用 SGD 优化器\n",
    "optimizer_SGD = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 使用 Adam 优化器\n",
    "optimizer_Adam = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd478ba7",
   "metadata": {},
   "source": [
    "训练过程（Training Process）\n",
    "训练神经网络涉及以下步骤：\n",
    "\n",
    "准备数据：通过 DataLoader 加载数据。\n",
    "定义损失函数和优化器。\n",
    "前向传播：计算模型的输出。\n",
    "计算损失：与目标进行比较，得到损失值。\n",
    "反向传播：通过 loss.backward() 计算梯度。\n",
    "更新参数：通过 optimizer.step() 更新模型的参数。\n",
    "重复上述步骤，直到达到预定的训练轮数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfa9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设已经定义好了模型、损失函数和优化器\n",
    "\n",
    "# 训练数据示例\n",
    "X = torch.randn(10, 2)  # 10 个样本，每个样本有 2 个特征\n",
    "Y = torch.randn(10, 1)  # 10 个目标标签\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(100):  # 训练 100 轮\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清除梯度\n",
    "    output = model(X)  # 前向传播\n",
    "    loss = criterion(output, Y)  # 计算损失\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新权重\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:  # 每 10 轮输出一次损失\n",
    "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2f8a1",
   "metadata": {},
   "source": [
    "测试与评估\n",
    "训练完成后，需要对模型进行测试和评估。\n",
    "\n",
    "常见的步骤包括：\n",
    "\n",
    "计算测试集的损失：测试模型在未见过的数据上的表现。\n",
    "计算准确率（Accuracy）：对于分类问题，计算正确预测的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你有测试集 X_test 和 Y_test\n",
    "model.eval()  # 设置模型为评估模式\n",
    "with torch.no_grad():  # 在评估过程中禁用梯度计算\n",
    "    output = model(X_test)\n",
    "    loss = criterion(output, Y_test)\n",
    "    print(f'Test Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684e655",
   "metadata": {},
   "source": [
    "神经网络类型\n",
    "前馈神经网络（Feedforward Neural Networks）：数据单向流动，从输入层到输出层，无反馈连接。\n",
    "卷积神经网络（Convolutional Neural Networks, CNNs）：适用于图像处理，使用卷积层提取空间特征。\n",
    "循环神经网络（Recurrent Neural Networks, RNNs）：适用于序列数据，如时间序列分析和自然语言处理，允许信息反馈循环。\n",
    "长短期记忆网络（Long Short-Term Memory, LSTM）：一种特殊的RNN，能够学习长期依赖关系"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
